#!/usr/bin/env python3
"""Web interface for POMS production monitoring."""

import os
import sys
import shlex

# Add parent directory (prodtools) to path to import as package
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

from flask import Flask, jsonify, request, redirect
from utils.poms_db import get_db_session, Job, DatasetInfo
from utils.db_analyzer import get_default_db_path
from utils.db_builder import build_db, locate_file
from utils.jobquery import Mu2eJobPars
import subprocess
import json
import os

app = Flask(__name__, 
            static_folder=os.path.join(parent_dir, 'web', 'static'))

# Global DB session
db_session = None

def _get_session():
    """Get or refresh database session to pick up any external changes."""
    global db_session
    if db_session is not None:
        try:
            db_session.close()
        except Exception:
            pass
    db_session = get_db_session(get_default_db_path())
    return db_session

def _rebuild_db(pattern: str = 'MDC202*'):
    """Rebuild the persistent DB from POMS JSONs and refresh the session."""
    build_db(pattern, get_default_db_path())
    return _get_session()

@app.route('/')
def index():
    """Main page - redirect to monitor."""
    return redirect('/monitor')

def _serve_html(filename):
    """Serve HTML files from the configured static folder."""
    return app.send_static_file(filename)

@app.route('/monitor')
def monitor():
    """Main monitor interface."""
    return _serve_html('monitor.html')

@app.route('/json2jobdef')
def json2jobdef_interface():
    """JSON to jobdef interface."""
    return _serve_html('json2jobdef.html')

@app.route('/json-editor')
def json_editor():
    """JSON file editor interface."""
    return _serve_html('json-editor.html')

@app.route('/api/reload', methods=['POST'])
def api_reload():
    """API endpoint to reload MDC JSON files."""
    try:
        _rebuild_db('MDC202*')
        return jsonify({'success': True, 'message': 'Database rebuilt successfully'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/jobs')
def api_jobs():
    """API endpoint for all job definitions."""
    # Refresh session to pick up any external database changes
    session = _get_session()
    jobs = []
    for job in session.query(Job).all():
        njobs = job.njobs or 0
        outputs = []
        for output in job.outputs:
            info = session.query(DatasetInfo).filter_by(dataset_name=output.dataset).one_or_none()
            nfiles = int(info.nfiles or 0) if info else 0
            nevts = int(info.nevts or 0) if info else 0
            
            # Format creation date
            creation_date_str = None
            if info and info.creation_date:
                if isinstance(info.creation_date, str):
                    creation_date_str = info.creation_date.split('T')[0]
                else:
                    creation_date_str = info.creation_date.strftime('%Y-%m-%d')
            
            outputs.append({
                'name': output.dataset,
                'nfiles': nfiles,
                'nevts': nevts,
                'events_per_file': round(nevts / nfiles, 2) if nfiles > 0 else 0.0,
                'avg_size_mb': round((info.total_size or 0) / nfiles / 1e6, 2) if nfiles else 0.0,
                'status': 'OK' if nfiles >= njobs else 'MISSING',
                'has_children': info.has_children if info else False,
                'creation_date': creation_date_str,
                'location': (info.location or 'N/A') if info else 'N/A'
            })
        
        # Extract setup script from tarball if available
        setup_script = ''
        if job.tarball:
            try:
                location = locate_file(job.tarball)
                # Extract file path from location (handle dict or string)
                if isinstance(location, dict):
                    file_path = location.get('full_path', '')
                    file_path = file_path.split(':', 1)[1] if ':' in file_path else file_path
                elif isinstance(location, str):
                    file_path = location.split(':', 1)[1] if ':' in location else location
                else:
                    file_path = None
                
                if file_path:
                    full_path = os.path.join(file_path, job.tarball)
                    if os.path.exists(full_path):
                        jp = Mu2eJobPars(full_path)
                        setup_script = jp.setup() or ''
            except Exception:
                # If extraction fails, leave setup_script empty
                pass
        
        jobs.append({
            'njobs': njobs,
            'tarball': job.tarball or '',
            'source_file': job.source_file or '',
            'setup_script': setup_script,
            'complete': job.complete or False,
            'avg_real_h': float(job.avg_real_h) if getattr(job, 'avg_real_h', None) is not None else None,
            'avg_vmhwm_gb': float(job.avg_vmhwm_gb) if getattr(job, 'avg_vmhwm_gb', None) is not None else None,
            'outputs': outputs
        })
    
    return jsonify(jobs)

@app.route('/api/dataset/<dataset_name>')
def api_dataset_info(dataset_name):
    """API endpoint to get dataset information using famtree."""
    use_stats = request.args.get('stats', 'false').lower() == 'true'
    
    # Create mermaid output directory
    mermaid_dir = os.path.join(parent_dir, 'web', 'mermaid')
    os.makedirs(mermaid_dir, exist_ok=True)
    
    # Change to mermaid directory to run famtree
    original_dir = os.getcwd()
    os.chdir(mermaid_dir)
    
    try:
        cmd = ['famtree']
        if use_stats:
            cmd.append('--stats')
        cmd.append(dataset_name)
        
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            return jsonify({'success': False, 'output': result.stderr.strip()})
        
        # Look for the .md file that famtree created
        # famtree uses first 4 parts of dataset name (without extension) for filename
        # e.g., nts.mu2e.CeEndpointMix1BBTriggered.MDC2025-000.root -> nts.mu2e.CeEndpointMix1BBTriggered.MDC2025-000.md
        parts = dataset_name.split('.')
        if len(parts) >= 4:
            # Take first 4 parts, remove extension if present
            base_name = '.'.join(parts[:4])
        else:
            # Fallback: remove common extensions
            base_name = dataset_name.replace('.art', '').replace('.root', '')
        md_filename = f'{base_name}.md'
        
        if os.path.exists(md_filename):
            with open(md_filename, 'r') as f:
                md_content = f.read()
            return jsonify({
                'success': True,
                'output': md_content,
                'has_mermaid': '```mermaid' in md_content
            })
        
        # Fallback if .md file not found
        return jsonify({
            'success': True,
            'output': result.stdout.strip(),
            'has_mermaid': False
        })
    finally:
        os.chdir(original_dir)

@app.route('/api/json2jobdef', methods=['POST'])
def api_json2jobdef():
    """API endpoint to run json2jobdef."""
    try:
        data = request.get_json()
        if not data.get('json_file'):
            return jsonify({'success': False, 'error': 'JSON file path is required'})
        
        # Build json2jobdef command with parameters
        cmd_parts = ['python3', os.path.join(parent_dir, 'utils', 'json2jobdef.py'),
                     '--json', data['json_file']]

        # Add optional parameters
        for key, flag in [('dsconf', '--dsconf'), ('desc', '--desc'),
                          ('index', '--index'), ('jobdefs', '--jobdefs')]:
            value = data.get(key)
            if value:
                cmd_parts.extend([flag, str(value)])

        if data.get('prod'):
            cmd_parts.append('--prod')
        if data.get('verbose'):
            cmd_parts.append('--verbose')

        # Build final command with optional SimJob setup
        json2jobdef_cmd = shlex.join(cmd_parts)
        simjob_release = data.get('simjob_release')
        if simjob_release:
            setup_cmd = f"source /cvmfs/mu2e.opensciencegrid.org/Musings/SimJob/{simjob_release}/setup.sh && {json2jobdef_cmd}"
            cmd = ['bash', '-c', setup_cmd]
        else:
            cmd = ['bash', '-c', json2jobdef_cmd]
        
        # Run json2jobdef (mkidxdef is now automatically run if --prod is set)
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        return jsonify({
            'success': result.returncode == 0,
            'stdout': result.stdout,
            'stderr': result.stderr,
            'command': ' '.join(cmd)
        })
        
    except subprocess.TimeoutExpired:
        return jsonify({'success': False, 'error': 'Command timed out after 120 seconds'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

def _normalize_file_path(file_path):
    """Normalize file paths - restore leading slash if needed, make absolute."""
    # Flask's <path:> converter strips leading slash, restore if needed
    if not os.path.isabs(file_path) and file_path.startswith(('exp/', 'home/', 'usr/')):
        file_path = '/' + file_path
    
    return file_path if os.path.isabs(file_path) else os.path.join(parent_dir, file_path)

@app.route('/api/json-files')
def api_json_files():
    """API endpoint to list JSON files."""
    try:
        data_dir = os.path.join(parent_dir, 'data')
        json_files = [
            {
                'path': rel_path,
                'name': filename,
                'directory': os.path.dirname(rel_path)
            }
            for root, _, files in os.walk(data_dir)
            for filename in files
            if filename.endswith('.json')
            for rel_path in [os.path.relpath(os.path.join(root, filename), parent_dir)]
        ]

        return jsonify({'success': True, 'files': json_files})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/json-file/<path:file_path>')
def api_get_json_file(file_path):
    """API endpoint to get JSON file content."""
    try:
        full_path = _normalize_file_path(file_path)
        
        if not os.path.exists(full_path):
            return jsonify({'success': False, 'error': f'File not found: {full_path}'})
        
        with open(full_path, 'r') as f:
            content = f.read()
        
        json.loads(content)  # Validate JSON
        return jsonify({'success': True, 'content': content, 'path': file_path})
    except json.JSONDecodeError as e:
        return jsonify({'success': False, 'error': f'Invalid JSON: {str(e)}'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/json-file/<path:file_path>', methods=['POST'])
def api_save_json_file(file_path):
    """API endpoint to save JSON file content."""
    try:
        content = request.get_json().get('content', '')
        json.loads(content)  # Validate JSON
        
        full_path = _normalize_file_path(file_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        
        with open(full_path, 'w') as f:
            f.write(content)
        
        return jsonify({'success': True, 'message': 'File saved successfully'})
    except json.JSONDecodeError as e:
        return jsonify({'success': False, 'error': f'Invalid JSON: {str(e)}'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

def main():
    """Run the Flask development server."""
    print("Starting POMS Monitor Web Interface...")
    print("Open your browser to: http://localhost:5000")
    print("Note: Make sure to source bin/setup.sh for famtree functionality")
    app.run(debug=False, host='0.0.0.0', port=5000)

if __name__ == '__main__':
    main()

